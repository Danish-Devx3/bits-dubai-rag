services:
  # ---------------------------------------------------------------------------
  # Vector Database: Qdrant
  # Used for storing vector embeddings for RAG.
  # ---------------------------------------------------------------------------
  qdrant:
    image: qdrant/qdrant:latest
    container_name: bits_qdrant
    restart: always
    ports:
      - "6333:6333"
    volumes:
      - qdrant_data:/qdrant/storage

  # ---------------------------------------------------------------------------
  # Local Ollama (for embeddings only - runs bge-m3)
  # ---------------------------------------------------------------------------
  ollama:
    image: ollama/ollama:latest
    container_name: bits_ollama
    restart: always
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama

  # Pull embedding model on startup
  ollama-init:
    image: curlimages/curl
    container_name: bits_ollama_init
    depends_on:
      - ollama
    restart: "no"
    command: >
      sh -c "echo 'Waiting for Ollama...' &&
             sleep 10 &&
             echo 'Pulling bge-m3 embedding model...' &&
             curl -X POST http://ollama:11434/api/pull -d '{\"name\": \"bge-m3\"}' &&
             echo 'Embedding model ready!'"

  # ---------------------------------------------------------------------------
  # Backend: NestJS
  # The core API server.
  # ---------------------------------------------------------------------------
  backend:
    image: ayaan27/bits-dubai-rag-backend:latest
    container_name: bits_backend
    restart: always
    ports:
      - "3001:3001"
    environment:
      # Database
      - DATABASE_URL=mongodb+srv://bits:bits123@youtube.v7xaz1a.mongodb.net/bits_dubai?retryWrites=true&w=majority&appName=Youtube
      - PORT=3001
      - FRONTEND_URL=http://localhost:3000
      - JWT_SECRET=dev-secret

      # Local Ollama for EMBEDDINGS
      - OLLAMA_EMBEDDING_URL=http://ollama:11434
      - OLLAMA_EMBEDDING_MODEL=bge-m3

      # Cloud LLM API (provide your API key in .env file)
      - OLLAMA_BASE_URL=${OLLAMA_BASE_URL:-https://api.ollama.com}
      - OLLAMA_API_KEY=${OLLAMA_API_KEY}
      - OLLAMA_LLM_MODEL=deepseek-r1

      # Qdrant Vector Database
      - QDRANT_URL=http://qdrant:6333
      - QDRANT_COLLECTION=bits_dubai_knowledge_base
    depends_on:
      - qdrant
      - ollama

  # ---------------------------------------------------------------------------
  # Frontend: Next.js
  # The web user interface.
  # ---------------------------------------------------------------------------
  frontend:
    image: ayaan27/bits-dubai-rag-frontend:latest
    container_name: bits_frontend
    restart: always
    ports:
      - "3000:3000"
    environment:
      - NEXT_PUBLIC_BACKEND_URL=http://3.92.146.237:3001
    depends_on:
      - backend

volumes:
  qdrant_data:
  ollama_data:
